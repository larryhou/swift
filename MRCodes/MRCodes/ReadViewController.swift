//
//  ViewController.swift
//  MRCodes
//
//  Created by larryhou on 13/12/2015.
//  Copyright Â© 2015 larryhou. All rights reserved.
//

import UIKit
import AVFoundation

class ReadViewController: UIViewController, AVCaptureMetadataOutputObjectsDelegate
{
    private var FocusContext:String?
    private var ExposureContext:String?
    private var LensContext:String?
    
    @IBOutlet weak var torchSwitcher: UISwitch!
    @IBOutlet weak var previewView: CameraPreviewView!
    @IBOutlet weak var metadataView: CameraMetadataView!
    
    private var session:AVCaptureSession!
    private var activeCamera:AVCaptureDevice?

    override func viewDidLoad()
    {
        super.viewDidLoad()
        
        session = AVCaptureSession()
        session.sessionPreset = .photo
        previewView.session = session
        (previewView.layer as! AVCaptureVideoPreviewLayer).videoGravity = .resizeAspectFill
        
        AVCaptureDevice.requestAccess(for: .video)
        { (success:Bool) -> Void in
            let status = AVCaptureDevice.authorizationStatus(for: .video)
            if success
            {
                self.configSession()
            }
            else
            {
                print(status, status.rawValue)
            }
        }
    }
    
    override func touchesBegan(_ touches: Set<UITouch>, with event: UIEvent?)
    {
        if let resultController = presentedViewController as? ResultViewController
        {
            resultController.animate(visible: false)
        }
    }
    
    override func viewWillAppear(_ animated: Bool)
    {
        super.viewWillAppear(animated)
        torchSwitcher.isHidden = true
        if !session.isRunning
        {
            session.startRunning()
        }
    }
    
    func applicationWillEnterForeground()
    {
        metadataView.setMetadataObjects([])
    }
    
    func findCamera(position:AVCaptureDevice.Position)->AVCaptureDevice!
    {
        let list = AVCaptureDevice.devices()
        for device in list
        {
            if device.position == position
            {
                return device
            }
        }
        
        return nil
    }
    
    func configSession()
    {
        session.beginConfiguration()
        
        guard let camera = findCamera(position: .back) else {return}
        self.activeCamera = camera
        
        do
        {
            let cameraInput = try AVCaptureDeviceInput(device: camera)
            if session.canAddInput(cameraInput)
            {
                session.addInput(cameraInput)
            }
            
            setupCamera(camera: camera)
        }
        catch {}
        
        let metadata = AVCaptureMetadataOutput()
        if session.canAddOutput(metadata)
        {
            session.addOutput(metadata)
            metadata.setMetadataObjectsDelegate(self, queue: .main)
            
            var metadataTypes = metadata.availableMetadataObjectTypes
            for i in 0..<metadataTypes.count
            {
                if metadataTypes[i] == .face
                {
                    metadataTypes.remove(at: i)
                    break
                }
            }
            
            metadata.metadataObjectTypes = metadataTypes
            print(metadata.availableMetadataObjectTypes)
        }
        
        session.commitConfiguration()
        session.startRunning()
    }
    
    func setupCamera(camera:AVCaptureDevice)
    {
        do
        {
            try camera.lockForConfiguration()
        }
        catch
        {
            return
        }
        
        if camera.isFocusModeSupported(.continuousAutoFocus)
        {
            camera.focusMode = .continuousAutoFocus
        }
        
        if camera.isAutoFocusRangeRestrictionSupported
        {
//            camera.autoFocusRangeRestriction = .near
        }
        
        if camera.isSmoothAutoFocusSupported
        {
            camera.isSmoothAutoFocusEnabled = true
        }
        
        camera.unlockForConfiguration()
        
//        camera.addObserver(self, forKeyPath: "adjustingFocus", options: .new, context: &FocusContext)
//        camera.addObserver(self, forKeyPath: "exposureDuration", options: .new, context: &ExposureContext)
        camera.addObserver(self, forKeyPath: "lensPosition", options: .new, context: &LensContext)
    }
    
    @IBAction func torchStatusChange(_ sender: UISwitch)
    {
        guard let camera = self.activeCamera else { return }
        guard camera.isTorchAvailable else {return}
        
        do { try camera.lockForConfiguration() } catch { return }
        
        if sender.isOn
        {
            if camera.isTorchModeSupported(.on)
            {
                try? camera.setTorchModeOn(level: AVCaptureDevice.maxAvailableTorchLevel)
            }
        }
        else
        {
            if camera.isTorchModeSupported(.off)
            {
                camera.torchMode = .off
            }
            
            checkTorchSwitcher(for: camera)
        }
        
        camera.unlockForConfiguration()
    }
    
    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey : Any]?, context: UnsafeMutableRawPointer?)
    {
        if context == &FocusContext || context == &ExposureContext || context == &LensContext, let camera = object as? AVCaptureDevice
        {
            print(camera.exposureDuration.seconds, camera.activeFormat.minExposureDuration.seconds, camera.activeFormat.maxExposureDuration.seconds,camera.iso, camera.lensPosition)
            checkTorchSwitcher(for: camera)
        }
    }
    
    func checkTorchSwitcher(`for` camera:AVCaptureDevice)
    {
        if camera.iso >= 400
        {
            torchSwitcher.isHidden = false;
        }
        else
        {
            torchSwitcher.isHidden = !camera.isTorchActive
        }
    }
    
    //MARK: metadataObjects processing
    func metadataOutput(_ output: AVCaptureMetadataOutput, didOutput metadataObjects: [AVMetadataObject], from connection: AVCaptureConnection)
    {
        var codes:[AVMetadataMachineReadableCodeObject] = []
        var faces:[AVMetadataFaceObject] = []
        
        let layer = previewView.layer as! AVCaptureVideoPreviewLayer
        for item in metadataObjects
        {
            guard let mrc = layer.transformedMetadataObject(for: item) else {continue}
            switch mrc
            {
                case is AVMetadataMachineReadableCodeObject:
                    codes.append(mrc as! AVMetadataMachineReadableCodeObject)
                
                case is AVMetadataFaceObject:
                    faces.append(mrc as! AVMetadataFaceObject)
                
                default:
                    print(mrc)
            }
        }
        DispatchQueue.main.async
        {
            self.metadataView.setMetadataObjects(codes)
            self.showMetadataObjects(self.metadataView.mrcObjects)
        }
    }
    
    func showMetadataObjects(_ objects:[AVMetadataMachineReadableCodeObject])
    {
        if let resultController = self.presentedViewController as? ResultViewController
        {
            resultController.mrcObjects = objects
            resultController.reload()
            
            resultController.animate(visible: true)
        }
        else
        {
            guard let resultController = storyboard?.instantiateViewController(withIdentifier: "ResultViewController") as? ResultViewController else
            {
                return
            }
            resultController.mrcObjects = objects
            resultController.view.frame = view.frame
            present(resultController, animated: false, completion: nil)
        }
        
    }
    
    //MARK: orientation
    override func viewWillTransition(to size: CGSize, with coordinator: UIViewControllerTransitionCoordinator)
    {
        super.viewWillTransition(to: size, with: coordinator)
        let orientation = UIDevice.current.orientation
        if orientation.isLandscape || orientation.isPortrait
        {
            let layer = previewView.layer as! AVCaptureVideoPreviewLayer
            if layer.connection != nil
            {
                layer.connection?.videoOrientation = AVCaptureVideoOrientation(rawValue: orientation.rawValue)!
            }
        }
        
    }
    
    override var supportedInterfaceOrientations: UIInterfaceOrientationMask { return .all }
    
    override var prefersStatusBarHidden: Bool { return true }

    override func didReceiveMemoryWarning()
    {
        super.didReceiveMemoryWarning()
    }

}

